{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks for waves decomposition (or discrete integral transform)\n",
    "\n",
    "This project aims to use ANNs as a no-brainer for the decomposition of different types of waves, that is, waves described by several functions other than just sine and cosine.\n",
    "\n",
    "In the case of complex exponentials, this can be seen as a way to obtain a Discrete Fourier Transform without the proper FFT methods. For Bessel functions, this would be equivalent to a Discrete Henkel Transform.\n",
    "\n",
    "The approach to ANN trained from FFT I saw functionally is from [@endolith](https://gist.github.com/endolith/98863221204541bf017b6cae71cb0a89), from which I used part of the code.\n",
    "\n",
    "This method is no way intended to be faster or more efficient than FFT, but more flexible and easy to expando to different types of waves.\n",
    "\n",
    "As a disclaimer, i'm new at GitHub and these calculations are still being made, so if you find something incomplete, it will be done in due time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=32; batch=10000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=np.arange(N);A=np.random.randn(batch, N) + 1j*np.random.randn(batch, N);K=np.random.randint(0, N, size=(batch, N));x=np.arange(N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo=np.zeros((batch, N), dtype='complex128');\n",
    "for j in range(batch):\n",
    "    for i in pos:\n",
    "        expo[j]+=A[j][i]*np.exp(K[j][i]*1j*2*np.pi*(x)/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=np.zeros_like(K, dtype='complex128');\n",
    "for j in range(batch):\n",
    "    for i in pos:\n",
    "        ft[j][K[j][i]]+=(A[j][i])*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([expo.real, expo.imag])\n",
    "Y = np.hstack([ft.real, ft.imag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 0s 48us/sample - loss: 959.4000\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 785.1089\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 636.7454\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 511.6430\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 407.0461\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 320.4333\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 249.4349\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 191.8537\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 145.7146\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 109.1995\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 80.6890\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 58.7425\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 42.1071\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 29.6872\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 20.5769\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 14.0067\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 9.3564\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 6.1295\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 3.9330\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 2.4706\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 1.5174\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 0.9105\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 0.5333\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 0.3044\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 0.1692\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 0.0915\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 0.0480\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 0.0245\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 0.0121\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 0.0058\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 0.0026\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 0.0012\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 5.0040e-04\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 2.0475e-04\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 8.0244e-05\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 3.0028e-05\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 1.0713e-05\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 3.6341e-06\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 1.1686e-06\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 3.5601e-07\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 1.0350e-07\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 3.0430e-080s - loss: 4.2868e\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 1.1015e-08\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 6.4355e-09\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 5.4721e-09\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 5.0947e-09\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 4.7180e-09\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 4.3367e-09\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 3.9940e-09\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 3.6401e-09\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 3.3129e-09\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 3.0226e-09\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 2.7539e-09\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 2.5082e-09\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 2.2822e-09\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 2.0672e-09\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 1.8750e-09\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 1.6936e-09\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 1.5472e-09\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 1.3945e-09\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 1.2505e-09\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 1.1333e-09\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 1.0253e-09\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 9.3211e-10\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 8.4934e-10\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 7.6970e-10\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 6.8925e-10\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 6.1968e-10\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 5.6163e-10\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 5.0283e-10\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 4.5413e-10\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 4.1515e-10\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 3.7481e-10\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 3.4086e-1 - 0s 17us/sample - loss: 3.3981e-10\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 3.0781e-10\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 2.7867e-10\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 2.5228e-10\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 2.2860e-10\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 2.0768e-10\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 1.8754e-10\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 1.7119e-10\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 1.5547e-10\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 1.4080e-10\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 1.2717e-10\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 1.1509e-10\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 1.0503e-10\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 9.5808e-11\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 8.8091e-11\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 8.0566e-11\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 7.3702e-110s - loss: 7.5409e\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 6.7417e-110s - loss: 6.9691e\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 6.1499e-11\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 5.6629e-11\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 5.2390e-11\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 4.8518e-11\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 4.5356e-11\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 4.1943e-11\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 3.8745e-110s - loss: 3.9129e-\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 3.6353e-11\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 3.4324e-11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b787d71608>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(N*2, input_dim=N*2, use_bias=False)])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, Y, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_DFT(x):\n",
    "    if len(x) != N:\n",
    "        raise ValueError(f'Input must be length {N}')\n",
    "    pred = model.predict(np.hstack([x.real, x.imag])[np.newaxis])[0]\n",
    "    result = pred[:N] + 1j*pred[N:]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN = ANN_DFT(data)\n",
    "FFT = np.fft.fft(data)\n",
    "print(f'ANN matches FFT: {np.allclose(ANN, FFT)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abs(ANN))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abs(FFT))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seno=[7*np.sin(3.5*2*np.pi*x/32) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sena=np.array(seno)\n",
    "ANN = ANN_DFT(sena)\n",
    "FFT = np.fft.fft(sena)\n",
    "print(f'ANN matches FFT: {np.allclose(ANN, FFT, rtol=1e-05, atol=1e-05)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sine series\n",
    "\n",
    "Now that we succesfully started with the best known example, the Fourier Transform, we go to a simpler case, Sine series.\n",
    "\n",
    "The only changes now are that we will only deal with Real entries (no \" dtype='complex128' \" specification needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=32; batch=10000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=np.arange(N);A=np.random.uniform(-50, 50, size=(batch, N));K=np.random.randint(0, N, size=(batch, N));x=np.arange(N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine=np.zeros((batch, N));\n",
    "for j in range(batch):\n",
    "    for i in pos:\n",
    "        sine[j]+=A[j][i]*np.sin((K[j][i])*np.pi*(x)/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=np.zeros_like(K);\n",
    "for j in range(batch):\n",
    "    for i in pos:\n",
    "        st[j][K[j][i]]+=(A[j][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/40\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 75.2960\n",
      "Epoch 2/40\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 41.9212\n",
      "Epoch 3/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 13.4149\n",
      "Epoch 4/40\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 1.0129\n",
      "Epoch 5/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.6782\n",
      "Epoch 6/40\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.6805\n",
      "Epoch 7/40\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.6811\n",
      "Epoch 8/40\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.68310s - loss: 0.6\n",
      "Epoch 9/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6842\n",
      "Epoch 10/40\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.6848\n",
      "Epoch 11/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6864\n",
      "Epoch 12/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6872\n",
      "Epoch 13/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6884\n",
      "Epoch 14/40\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.6894\n",
      "Epoch 15/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6894\n",
      "Epoch 16/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6905\n",
      "Epoch 17/40\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.6915\n",
      "Epoch 18/40\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.6913\n",
      "Epoch 19/40\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.6917\n",
      "Epoch 20/40\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.6927\n",
      "Epoch 21/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6921\n",
      "Epoch 22/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6941\n",
      "Epoch 23/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.6931\n",
      "Epoch 24/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6932\n",
      "Epoch 25/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6935\n",
      "Epoch 26/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6942\n",
      "Epoch 27/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6934\n",
      "Epoch 28/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6939\n",
      "Epoch 29/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.6943\n",
      "Epoch 30/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6962\n",
      "Epoch 31/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.6949\n",
      "Epoch 32/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6944\n",
      "Epoch 33/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6946\n",
      "Epoch 34/40\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.6950\n",
      "Epoch 35/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6953\n",
      "Epoch 36/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6948\n",
      "Epoch 37/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6958\n",
      "Epoch 38/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6951\n",
      "Epoch 39/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6957\n",
      "Epoch 40/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.6951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23eb38184c8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(N, input_dim=N, use_bias=True)])\n",
    "model.compile(loss='huber_loss', optimizer='adam')\n",
    "model.fit(sine, st, epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/40\n",
      "10000/10000 [==============================] - 1s 72us/sample - loss: 7.7898\n",
      "Epoch 2/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 6.4760\n",
      "Epoch 3/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 5.0525\n",
      "Epoch 4/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 3.4735\n",
      "Epoch 5/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 1.7132\n",
      "Epoch 6/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.4358\n",
      "Epoch 7/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.1979\n",
      "Epoch 8/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.1501\n",
      "Epoch 9/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.1337\n",
      "Epoch 10/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.1191\n",
      "Epoch 11/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.1096\n",
      "Epoch 12/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.1037\n",
      "Epoch 13/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0998\n",
      "Epoch 14/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0993\n",
      "Epoch 15/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0979\n",
      "Epoch 16/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0982\n",
      "Epoch 17/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.0979\n",
      "Epoch 18/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0979\n",
      "Epoch 19/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0981\n",
      "Epoch 20/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0989\n",
      "Epoch 21/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0990\n",
      "Epoch 22/40\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.0981\n",
      "Epoch 23/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.0977\n",
      "Epoch 24/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0982\n",
      "Epoch 25/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0977\n",
      "Epoch 26/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0966\n",
      "Epoch 27/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0980\n",
      "Epoch 28/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0973\n",
      "Epoch 29/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.0963\n",
      "Epoch 30/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0961\n",
      "Epoch 31/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.0963\n",
      "Epoch 32/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0965\n",
      "Epoch 33/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.0956\n",
      "Epoch 34/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.0943\n",
      "Epoch 35/40\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.0944\n",
      "Epoch 36/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0923\n",
      "Epoch 37/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0906\n",
      "Epoch 38/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0907\n",
      "Epoch 39/40\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0885\n",
      "Epoch 40/40\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23eb0b3d1c8>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(N, input_dim=N, use_bias=True)])\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer='adam')\n",
    "model.fit(sine, st, epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.500185"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosseno=[30*np.sin(9*np.pi*x/N) for x in pos]\n",
    "\n",
    "cossena=np.array([cosseno])\n",
    "pred=model.predict(cossena)\n",
    "max(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(cossena[0], 'blue')\n",
    "plt.plot(pred[0], 'red')\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
